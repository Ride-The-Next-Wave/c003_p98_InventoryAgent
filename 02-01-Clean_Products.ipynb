{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Clean Products List\n",
    "\n",
    "This notebook cleans the prooduct raw data in preparation for modeling. The ultimate goal is to match cleaned articles to the products based on the provided data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./intermediate_data/01-Collect/Raw_Products_List.json', 'r') as f:\n",
    "    categories = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract information for each product category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_product_info(element):\n",
    "    try:\n",
    "        name_elem = element.find(['a', 'span', 'div'], text=True)\n",
    "        if name_elem:\n",
    "            name = name_elem.get_text(strip=True)\n",
    "            if len(name) > 5:\n",
    "                return {\n",
    "                    'name': name,\n",
    "                    'description': name,\n",
    "                    'part_number': None,\n",
    "                    'quantity_available': None\n",
    "                }\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract information for all product categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_category_products(category_url):\n",
    "    try:\n",
    "        response = requests.get(category_url, headers=HEADERS)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        products = []\n",
    "        elements = soup.find_all(['div', 'tr'], class_=re.compile(r'product|item|row', re.I))\n",
    "\n",
    "        for el in elements[:100]:\n",
    "            product = extract_product_info(el)\n",
    "            if product:\n",
    "                products.append(product)\n",
    "        print(f\"Found {len(products)} products\")\n",
    "        return products\n",
    "    except Exception as e:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape and organize extracted information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_products = []\n",
    "for i, cat in enumerate(categories[:20]): \n",
    "    products = scrape_category_products(cat['url'])\n",
    "    for product in products:\n",
    "        product['category'] = cat['name']\n",
    "        product['main_category'] = cat['category']\n",
    "        all_products.append(product)\n",
    "    time.sleep(2)\n",
    "\n",
    "results = {\n",
    "    'categories': categories,\n",
    "    'products': all_products,\n",
    "    'summary': {\n",
    "        'total_categories': len(categories),\n",
    "        'total_products': len(all_products)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Cleaned Product List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./intermediate_data/02-Clean/Cleaned_Products_List.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Authors:**\n",
    "[Sai Keertana Lakku](mailto:saikeertana005@gmail.com),\n",
    "[Zhen Zhuang](mailto:zhuangzhen17cs@gmail.com),\n",
    "[Nick Capaldini](mailto:nick.capaldini@ridethenextwave.com), Ride The Next Wave, Jun 13, 2025\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (recommendation_libraries)",
   "language": "python",
   "name": "recommendation_libraries"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
